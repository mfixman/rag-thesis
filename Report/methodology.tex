\section{Methodology}

\newcommand{\cats}{7}
\newcommand{\baseqs}{68}
\newcommand{\things}{312}
\newcommand{\qs}{3840}

\subsection{Source Data Preparation}

Our source data is prepared by extending the ideas presented by Yu et al\cite{factual_recall}.
Instead of using one simple question, our approach consists of separating this data into \cats{} categories, where each category has a set of base questions and another set of objects that are paired together and presented to our models.

This work contains \cats{} categories in the configuration shown by \cref{categories_numbers}, for a total of \qs{} questions.
The full list of questions can be found in \cref{appendixA}.

\begin{table}[h]
	\centering
	\footnotesize
	\begin{tabular}{l | r r r}
		\toprule
			\bfseries Category & \bfseries Questions & \bfseries Objects & \bfseries Total \\
		\midrule
			Person           & 14 &  47 &  658 \\
			City             & 14 &  60 &  840 \\
			Principle        & 10 &  30 &  300 \\
			Element          & 10 &  35 &  350 \\
			Book             & 10 &  45 &  450 \\
			Painting         & 14 &  39 &  546 \\
			Historical Event & 6  &  56 &  336 \\
		\midrule
			Total & \baseqs{} & \things{} & \qs{} \\
		\bottomrule
	\end{tabular}
	\caption{The amount of questions for each category. The full list of questions can be found in \cref{appendixA}. This is still a work in progress and I expect to add more questions.}
	\label{categories_numbers}
\end{table}

We enhance the zero-shot learning prompt used by Brown~et.~al\cite{fewshotlearners} by using the prompt format example format presented by Jiang~et.~al\cite{how_can_we_know} for calibrating the T5 language model by adding both the question and the first part of the answer.

\begin{table}[h]
	\setlength{\fboxsep}{0pt}
	\setlength{\fboxrule}{1pt}
	\newcommand{\rep}[1]{\fcolorbox{Gray}{Gray!80}{\textit{#1}}}

	\centering
	\scriptsize
	\begin{tabular}{l l | l}
		\toprule
			\bfseries Base Question & \bfseries Object & \bfseries Final Question \\
		\midrule
			\begin{minipage}{.39\textwidth}
				\ttfamily
				What is the date of birth of \rep{\{person\}}? \\ The date of birth of \rep{\{person\}} is \\[1ex]
				In what city was \rep{\{person\}} born? \\ \rep{\{person\}} was born in \\[1ex]
				What country is \rep{\{city\}} in? \\ \rep{\{city\}} is in
			\end{minipage} &
			\begin{minipage}{.16\textwidth}
				\ttfamily
				\textcolor{Red}{Che Guevara} \\[1ex]
				\textcolor{Sepia}{Confucius} \\[1ex]
				\textcolor{BurntOrange}{Cairo} \\[1ex]
				\textcolor{ForestGreen}{Mumbai}
			\end{minipage} &
			\begin{minipage}{.45\textwidth}
				\ttfamily
				What is the date of birth of \textcolor{Red}{Che Guevara}? \\ The date of birth of \textcolor{Red}{Che Guevara} is \\[1ex]
				What is the date of birth of \textcolor{Sepia}{Confucius}? \\ The date of birth of \textcolor{Sepia}{Confucius} is \\[1ex]
				In what city was \textcolor{Red}{Che Guevara} born? \\ \textcolor{Red}{Che Guevara} was born in \\[1ex]
				In what city was \textcolor{Sepia}{Confucius} born? \\ \textcolor{Sepia}{Confucius} was born in \\[1ex]
				What country is \textcolor{BurntOrange}{Cairo} in? \\ \textcolor{BurntOrange}{Cairo} is in \\[1ex]
				What country is \textcolor{ForestGreen}{Mumbai} in? \\ \textcolor{ForestGreen}{Mumbai} is in
			\end{minipage} \\
		\bottomrule
	\end{tabular}
	\caption{Some examples of the base-question and object generation that are fed to the models for finding parametric answers.}
\end{table}

\subsection{Prompting}

Previous research on this area uses a very simple query format without any prompt before the question\cite{how_can_we_know}\cite{factual_recall}.
While this technique is sufficient when solely looking for answers, its answers cause problems when calculating the likelihood and perplexity of the answers.

To prevent language models from adding context in the problem of zero-shot learning, it's necessary to program a custom prompt\cite{beyondfewshot}.
Due to the dual-prompting nature of this problem for finding parametric and counterparametric knowledge, two different prompts are defined as defined in \cref{prompts}.

\begin{figure}[h]
	\fbox{
		\begin{minipage}[c][50pt]{.45\textwidth}
			\ttfamily
			Answer the following question in a few words and with no formatting.
		\end{minipage}
	} \hfill{}
	\fbox{
		\begin{minipage}[c][50pt]{.45\textwidth}
			\ttfamily
			Answer the following question using the previous context in a few words and with no formatting.
		\end{minipage}
	}
	\caption{The prompts appended before the questions used for finding parametric and counterparametric data, respectively.}
	\label{prompts}
\end{figure}
