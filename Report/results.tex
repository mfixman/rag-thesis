\section{Results}

Some results I want to show.
\begin{itemize}
	\item Larger models tend to prefer parametric knowledge over contextual knowledge.
		\begin{itemize}
			\item This is the case in ``Characterizing Mechanisms for Factual Recall in Language Models''\cite{factual_recall}, but I'm proving this on a larger set of question.
			\item This is using exact match. Maybe attempting Unigram F\textsubscript{1} would produce interesting results\cite{kilt}.
		\end{itemize}
	\item How this compares between Decoder-only models, Seq2Seq models, and Retrieval-Augmented Language Models.
	\item How does the perplexity between parametric answers and contextual answers compare within the same model.
		\begin{itemize}
			\item From the perplexity alone, can we predict whether an answer came from the model's memory or from the context?
			\item It might be worth experimenting this with factual answers in the context, to simulate a RAG-difference detector.
		\end{itemize}
	\item Is there any correlation between the perplexity of the parametric and contextual answer \textit{without any context} and which one will be chosen when adding context?
		\begin{itemize}
			\item This one is interesting, but I'm not sure we'll get significative results.
		\end{itemize}
	\item Interesting \textsl{``Other''} results.
	\item \textbf{Anything else}?
\end{itemize}
